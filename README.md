# Retention_IA_Platform_Backend
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Google Gemini](https://img.shields.io/badge/Google%20Gemini-8E75B2?style=for-the-badge&logo=google&logoColor=white)
![Git](https://img.shields.io/badge/Git-F05032?style=flat&logo=git&logoColor=white) 

##  PrÃ©sentation
RetentionAI est le moteur d'intelligence dÃ©cisionnelle pour les RH. Ce backend expose une API REST sÃ©curisÃ©e permettant de prÃ©dire le risque de dÃ©part des employÃ©s et de gÃ©nÃ©rer des stratÃ©gies de rÃ©tention via l'IA GÃ©nÃ©rative 

## Table des matiÃ¨res

1. [PrÃ©sentation](#prÃ©sentation)
2. [Objectifs du Projet](#objectifs-du-projet)
3. [Architecture Globale du Projet](#architecture-globale-du-projet)
4. [Stack Technique](#stack-technique)
5. [Installation et Lancement](#installation--lancement)
6. [Tests](#tests)
7. [Pipeline Machine Learning](#pipeline-machine-learning)
8. [Documentation de lâ€™API](#documentation-de-lapi)
9. [IA GÃ©nÃ©rative et Prompt Engineering](#ia-gÃ©nÃ©rative-et-prompt-engineering)
10. [Tests Unitaires Backend](#tests-unitaires-backend)
11. [Structure du Projet](#structure-du-projet)
12. [Auteur](#auteur)


## Objectifs du Projet

### Business
*   **Anticiper** : Identifier les profils Ã  haut risque de dÃ©mission avant qu'ils ne quittent l'entreprise.
*   **Agir** : Proposer des actions RH concrÃ¨tes et personnalisÃ©es pour chaque collaborateur.
*   **Optimiser** : RÃ©duire les coÃ»ts liÃ©s au turnover et prÃ©server les talents clÃ©s.

### Techniques
*   Mise en Å“uvre d'un pipeline ML supervisÃ© (Scikit-Learn).
*   DÃ©veloppement d'une API sÃ©curisÃ©e sous FastAPI.
*   IntÃ©gration d'une IA gÃ©nÃ©rative (Gemini) pour les recommandations.
*   Conteneurisation via Docker pour un dÃ©ploiement industriel.
##  Architecture Globale du projet

Le projet est entiÃ¨rement conteneurisÃ© via Docker. Le backend (FastAPI) agit comme une passerelle d'orchestration entre le frontend (React), la base de donnÃ©es et les services IA externes.

```mermaid
graph LR
    %% --- DEFINITION DES COULEURS ---
    classDef docker fill:#BBDEFB,stroke:#1565C0,stroke-width:2px,color:#000;
    classDef ext fill:#E1BEE7,stroke:#7B1FA2,stroke-width:2px,color:#000;
    classDef db fill:#FFE0B2,stroke:#EF6C00,stroke-width:2px,color:#000;
    classDef ai fill:#C8E6C9,stroke:#2E7D32,stroke-width:2px,color:#000;

    linkStyle default stroke:#37474F,stroke-width:2px;

    %% --- ACTEUR ---
    RH((ðŸ‘¤ Utilisateur RH)):::ext

    %% --- ZONE DOCKER COMPOSE ---
    subgraph DC [ðŸ³ Docker Compose]
        direction LR
        UI[ Frontend ]:::docker
        
        subgraph Backend [ Backend API]
            direction TB
            Router[ FastAPI Router]:::docker
            Logic[ Backend Logic + ML Pipeline]:::docker
        end
        
        DB[( PostgreSQL DB)]:::db
    end

    %% --- ZONE IA EXTERNE ---
    subgraph AI_External [â˜ï¸ IA Externe]
        Gemini[ðŸª„ Generative AI Gemini]:::ai
    end

    %% --- CONNEXIONS ---
    RH -->|Http| UI
    UI -->|API Call| Router
    Router --> Logic
    Logic -->|SQLAlchemy| DB

    %% Connexion vers IA gÃ©nÃ©rative externe
    Logic -.->|GÃ©nÃ©ration plan de rÃ©tention| Gemini

    %% Style des cadres
    style DC fill:#FFFFFF,stroke:#1565C0,stroke-width:3px,stroke-dasharray:5 5,color:#000000,font-size:16px
    style AI_External fill:#F1F8E9,stroke:#2E7D32,stroke-width:2px,stroke-dasharray:5 5,color:#000000,font-size:14px


```
##  Stack Technique
- **Framework :** FastAPI (Python )
- **Machine Learning :** Scikit-Learn, Pandas,GridSearchCV, MLflow,Joblib
- **IA GÃ©nÃ©rative :** Google Gemini API 
- **Base de donnÃ©es :** PostgreSQL (SQLAlchemy)
- **SÃ©curitÃ© :** JWT (JSON Web Tokens) & argon2
- **Conteneurisation :** Docker / Docker-compose


## Installation & Lancement

### 1. Cloner le projet
```bash
git clone https://github.com/khadija199904/Retention_IA_Platform_Backend.git
cd Retention_IA_Platform_Backend
```

### 2. Environnement(.env)
1. **Env** : CrÃ©er un fichier `.env` avec vos clÃ©s API et accÃ¨s DB.
```bash
POSTGRES_USER=USE
POSTGRES_PASSWORD=PASSWORD
POSTGRES_HOST=localhost
POSTGRES_DB=DN_NAME
POSTGRES_PORT=PORT

GEMINI_API_KEY = "AI**************************************"
SECRET_KEY = "************************"
```

### 3. Lancement avec Docker (RecommandÃ©)
```bash
 docker-compose up --build
```
L'API sera accessible sur http://localhost:8000. La documentation Swagger est disponible sur /docs.

## Tests
```bash
pytest -v
```
## Pipeline Machine Learning
### Flux complet du 
```mermaid
graph LR
    %% --- DEFINITION DES COULEURS ---
    classDef step fill:#BBDEFB,stroke:#1565C0,stroke-width:2px,color:#000;
    classDef preprocess fill:#FFE0B2,stroke:#EF6C00,stroke-width:2px,color:#000;
    classDef train fill:#C8E6C9,stroke:#2E7D32,stroke-width:2px,color:#000;
    classDef optimize fill:#E1BEE7,stroke:#7B1FA2,stroke-width:2px,color:#000;
    classDef track fill:#F1F8E9,stroke:#2E7D32,stroke-width:2px,color:#000;

    %% --- PIPELINE ML ---
    EDA[Analyse Exploratoire EDA - CorrÃ©lations: Salaire, Distance, Satisfaction]:::step
    Preprocess[PrÃ©processing - Suppression colonnes inutiles, OneHotEncoder, StandardScaler]:::preprocess
    Training[EntraÃ®nement - RÃ©gression Logistique vs Random Forest]:::train
    Optimization[Optimisation - GridSearchCV pour meilleurs paramÃ¨tres]:::optimize
    Tracking[Tracking des mÃ©triques - MLflow : PrÃ©cision, Recall, AUC]:::track

    %% --- FLUX ---
    EDA --> Preprocess
    Preprocess --> Training
    Training --> Optimization
    Optimization --> Tracking

```
### Interface MLflow â€“Visualisation des ExpÃ©riences

Le suivi MLflow permet de visualiser facilement les mÃ©triques, paramÃ¨tres et modÃ¨les. Voici un exemple dâ€™affichage :
Interface : ![mlf Experiment](./images/Interface.png)
ModÃ¨les EntraÃ®nÃ©s : ![ModÃ¨les](./images/Traning.png)

# Documentation de l'API

## Authentification

| MÃ©thode | Endpoint  | Description |
|---------|-----------|-------------|
| POST    | /register | CrÃ©ation d'un compte RH (mot de passe hashÃ© via Bcrypt). |
| POST    | /login    | Retourne un Access Token JWT (valide 30 min). |

## Endpoints MÃ©tier (SÃ©curisÃ©s par JWT)

| MÃ©thode | Endpoint                  | Description |
|---------|---------------------------|-------------|
| POST    | /predict                  | Calcule la probabilitÃ© de dÃ©part dâ€™un employÃ©. |
| POST    | /generate-retention-plan  | Calcule le risque via le modÃ¨le ML. Si le risque > 50%, dÃ©clenche l'IA gÃ©nÃ©rative pour crÃ©er 3 actions concrÃ¨tes. Enregistre la transaction dans l'historique PostgreSQL. |

##  IA GÃ©nÃ©rative et Prompt Engineering

Le systÃ¨me utilise un prompt dynamique envoyÃ© Ã  l'IA externe pour assurer la pertinence des conseils :
"Agis comme un expert RH. Voici les informations sur lâ€™employÃ© : [Age, JobRole, Satisfaction, Performance]. Ce salariÃ© a un risque Ã©levÃ© de dÃ©part (score : [Proba]%). Propose 3 actions concrÃ¨tes et opÃ©rationnelles pour le retenir."
## Workflow API

```mermaid
sequenceDiagram
    participant B as Backend (FastAPI)
    participant DB as Base de DonnÃ©es (PostgreSQL)
    participant ML as ML Pipeline (Local)
    participant G as Google Gemini (GenAI)

    Note over B: Gestion des endpoints API et logique interne

    %% Ã‰tape 1 : Authentification
    B->>DB: VÃ©rification / CrÃ©ation User (register/login)
    DB-->>B: Retour User / Confirmation
    B-->>B: GÃ©nÃ©ration JWT Token

    %% Ã‰tape 2 : PrÃ©diction churn
    B->>B: Validation Token & DonnÃ©es employÃ©
    B->>ML: Calcul churn probability
    ML-->>B: ProbabilitÃ© de churn

    %% Ã‰tape 3 : GÃ©nÃ©ration plan de rÃ©tention si nÃ©cessaire
    alt Risque > 50%
        B->>G: GÃ©nÃ©ration plan de rÃ©tention
        G-->>B: Retour 3 actions concrÃ¨tes
    else Risque â‰¤ 50%
        Note over B: Pas d'action gÃ©nÃ©rÃ©e
    end

    %% Ã‰tape 4 : Logging
    B->>DB: Sauvegarde logs et rÃ©sultats
```

### Gestion des erreurs

|  Incident  |   Code HTTP |
|------------|--------------|
| champs vides | 40O Bad request |
| Token invalide ou absent | 401 Unauthorized |
| DonnÃ©es envoyÃ©es invalides | 422 Unprocessable Entity |
| Hugging Face Timeout | 504 Gateway Timeout |
| Hugging Face Erreur RÃ©seau | 502 Bad Gateway |
| Gemini indisponible | 503 Service Unavailable |
| RÃ©ponse Gemini mal formÃ©e / JSON invalide | 500 Internal Server Error |
| Score de classification trop faible | 400 Bad Request |

## Tests Unitaires (Backend)
Pour lancer les tests (nÃ©cessite Python localement) :
```bash
cd backend
# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate
# Installer les dÃ©pendances
pip install -r requirements.txt
# Lancer les tests
pytest  -v 

```

##  Structure du Projet : 
```bash
RetentionAI/
â”‚
â”œâ”€â”€ .github/workflows/              # Automatisation CI/CD
â”‚   â””â”€â”€ test.yml                    # Workflow pour tests et build Docker
â”‚
â”œâ”€â”€ api_app/                        # Application Backend FastAPI
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                     # Point d'entrÃ©e de l'API
â”‚   â”œâ”€â”€ database.py                 # Configuration SQLAlchemy & Connexion
â”‚   â”œâ”€â”€ dependencies.py             # DÃ©pendances (get_db, oauth2_scheme)
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                       # ParamÃ¨tres globaux
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py               # Gestion du .env (pydantic-settings)
â”‚   â”‚   â””â”€â”€ security.py             # Logique JWT et Bcrypt
â”‚   â”‚
â”‚   â”œâ”€â”€ crud/                       # OpÃ©rations Base de DonnÃ©es
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ create_user.py          # Logique de crÃ©ation d'utilisateurs RH
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                     # ModÃ¨les SQLAlchemy (ORM)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ users.py                # Table "users"
â”‚   â”‚   â””â”€â”€ predictions.py          # Table "predictions_history"
â”‚   â”‚
â”‚   â”œâ”€â”€ outils/                     # Utilitaires transverses
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ get_prediction.py
â”‚   â”‚   â”œâ”€â”€ build_rh_prompt.py
â”‚   â”‚   â”œâ”€â”€ load_model.py
â”‚   â”‚   â””â”€â”€ predictions_history.py        # Sauvegarde des rÃ©sultats en DB
â”‚   â”‚
â”‚   â”œâ”€â”€ routers/                    # Points d'accÃ¨s (Endpoints)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ predict.py              # POST /predict et /generate-plan
â”‚   â”‚   â”œâ”€â”€ analyse.py              # POST /predict et /generate-plan
â”‚   â”‚   â””â”€â”€ auth.py                 # POST /register et /login
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/                    # Validation Pydantic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ employe_schema.py             # Validation des donnÃ©es employÃ© 
â”‚   â”‚   â”œâ”€â”€ generate_plan_schema.py        # SchÃ©mas de repone /generate-retention-plan
â”‚   â”‚   â”œâ”€â”€ user_schema.py                 # SchÃ©mas UserCreate
â”‚   â”‚   â””â”€â”€ predict_schema.py              # SchÃ©mas de rÃ©ponse prÃ©diction
â”‚   â”‚
â”‚   â””â”€â”€ services/                   # Appels aux IA Externes
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ generative_IA.py           # Logique  Google Gemini
â”‚
â”œâ”€â”€ ml/                             # Partie Science des DonnÃ©es
â”‚   â”œâ”€â”€ artifacts/                  # Matrice de confudion , repport classication , ROC courbe
â”‚   â”œâ”€â”€ saved_models/               # ModÃ¨les entraÃ®nÃ©s (model.pkl)
â”‚   â”œâ”€â”€ Attrition-RH-Data.csv       # Dataset brut
â”‚   â”œâ”€â”€ Fonctions.py                # Fonctions de traitement ML (RIAF-10)
â”‚   â”œâ”€â”€ analyse-preparation.ipynb   # Notebook de l'EDA
â”‚   â””â”€â”€ pipeline.py                 # Script d'entraÃ®nement et sauvgarde du moÃ¨le
â”‚
â”œâ”€â”€ Tests/                          # Tests Unitaires et IntÃ©gration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_LLM_response.py        # Test des appels API Gemini
â”‚   â””â”€â”€ test_load_model.py          # Test de chargement du fichier .pkl
â”‚
â”œâ”€â”€ .dockerignore                   # Fichiers Ã  exclure du conteneur
â”œâ”€â”€ .env                            # Variables secrÃ¨tes (ClÃ©s API, DB URL)
â”œâ”€â”€ .gitignore                      # Fichiers Ã  exclure de Git
â”œâ”€â”€ Dockerfile                      # Instruction de build de l'image
â”œâ”€â”€ docker-compose.yml              # Orchestration (API + PostgreSQL)
â”œâ”€â”€ README.md                       # Documentation complÃ¨te
â””â”€â”€ requirements.txt                # Liste des dÃ©pendances Python
```

## Auteur

**Nom :** KHADIJA ELABBIOUI  
**Email :** khadija.elabbioui1999@gmail.com  
**LinkedIn :** [linkedin.com/in/khadija-elabbioui](https://www.linkedin.com/in/khadija-elabbioui-308499216/)  
**GitHub :** [github.com/ton-github](https://github.com/khadija199904)